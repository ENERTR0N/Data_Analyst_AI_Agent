{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664c335e-acba-476e-a5c8-6aceb478c3d3",
   "metadata": {},
   "source": [
    "<h2>Import Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe6d7ba-3c41-4440-a9bd-eb5775a4c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import plotly.express as px\n",
    "import google.generativeai as genai\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload, Layout, VBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1e07c-7ce2-443e-90ef-a4f3465dd75a",
   "metadata": {},
   "source": [
    "<h2>Extracting Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbee7263-641a-4820-9f4d-16a7075c5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Google Gemini API\n",
    "genai.configure(api_key=\"\")  # Replace with your actual API key\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Initialize global dataframe\n",
    "df = None\n",
    "\n",
    "def extract_table_from_pdf(file_path):\n",
    "    \"\"\"Extracts tables from a pdf and converts them into a pandas dataframe.\"\"\"\n",
    "    tables = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            extracted_tables = page.extract_tables()\n",
    "            for table in extracted_tables:\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])  # First row as headers\n",
    "                tables.append(df)\n",
    "    \n",
    "    if tables:\n",
    "        return pd.concat(tables, ignore_index=True)  # Merge tables if multiple found\n",
    "    return None  # No tables found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd54de-6bb2-47c1-a69d-0f6da904d904",
   "metadata": {},
   "source": [
    "<h2>Processing File</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa1fa98-6f87-401f-a894-870f81809a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    \"\"\"Processes uploaded files and extracts structured data.\"\"\"\n",
    "    try:\n",
    "        content = io.BytesIO(file[\"content\"])\n",
    "        filename = file[\"metadata\"][\"name\"]\n",
    "\n",
    "        if filename.endswith('.csv'):\n",
    "            return pd.read_csv(content)\n",
    "        elif filename.endswith('.xlsx'):\n",
    "            return pd.read_excel(content)\n",
    "        elif filename.endswith('.pdf'):\n",
    "            df = extract_table_from_pdf(content)\n",
    "            return df if df is not None else pd.DataFrame({\"Message\": [\"No tables found\"]})\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing file: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cd7dd-847d-4d55-a47e-a125cd6a6d9c",
   "metadata": {},
   "source": [
    "<h2>For Queries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6832d4e-60a1-4bc5-88d4-bb4401188174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "\n",
    "def clean_json_response(response):\n",
    "    \"\"\"Extracts and cleans Python or JSON code from LLM responses while preserving correct indentation.\"\"\"\n",
    "    match = re.search(r\"```(?:json|python)?\\s*\\n([\\s\\S]+?)\\n```\", response)\n",
    "    if match:\n",
    "        code_block = match.group(1)\n",
    "        \n",
    "        # Use textwrap.dedent() to remove unwanted leading spaces while preserving relative indentation\n",
    "        cleaned_code = textwrap.dedent(code_block)\n",
    "        \n",
    "        # Strip any accidental leading/trailing blank lines\n",
    "        return cleaned_code.strip()\n",
    "\n",
    "    return response  # Return original if no code block found\n",
    "\n",
    "def query_gemini(prompt_text):\n",
    "    \"\"\"Function to call Google Gemini API for processing queries\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-2.0-flash\")  # Use correct Gemini model\n",
    "        response = model.generate_content(prompt_text)\n",
    "        return response.text.strip() if response and response.text else \"No response\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error querying Gemini API: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c07c3-f88a-4a37-a6b8-0c3206a9be67",
   "metadata": {},
   "source": [
    "<h2>Generating Visualizations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5aa55bf-4c84-4e65-9a1c-c135f1ab0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def generate_visualization(df, query):\n",
    "    try:\n",
    "        prompt_text = f\"\"\"\n",
    "        Given the columns: {', '.join(df.columns)}, and the query: {query}, \n",
    "        Give plotly code for the same and try to keep the format similar to this:\n",
    "        df[y_col] = pd.to_numeric(df[y_col], errors='coerce')  # Convert if needed\n",
    "        df_sorted = df.sort_values(by=y_col, ascending=True)  # Sort correctly\n",
    "        \n",
    "        chart_mapping = {{\n",
    "            \"pie\": px.pie(df_sorted, names=x_col, values=y_col, title=query),\n",
    "            \"bar\": px.bar(df_sorted, x=x_col, y=y_col, title=query),\n",
    "            \"line\": px.line(df_sorted, x=x_col, y=y_col, title=query),\n",
    "            \"scatter\": px.scatter(df_sorted, x=x_col, y=y_col, title=query),\n",
    "        }}\n",
    "\n",
    "        fig = chart_mapping.get(chart_type, px.bar(df, x=x_col, y=y_col, title=query))\n",
    "        fig.show().\n",
    "        and dont give anything more than the things present in this format.\n",
    "        Also dont give import statements or function declarations or comments. I Just\n",
    "        need the code exactly like the format I specified so that I can put it myself in a \n",
    "        function. Also give a print statement for the dataframe in the end.\n",
    "        \"\"\"\n",
    "        response = query_gemini(prompt_text)\n",
    "        # print(\"üì¢ Gemini API Raw Response:\", response)  # Debugging output\n",
    "\n",
    "        # Clean response if wrapped in markdown\n",
    "        cleaned_response = clean_json_response(response)\n",
    "        \n",
    "        # Dedent the code to fix indentation issues\n",
    "        formatted_code = textwrap.dedent(cleaned_response)\n",
    "\n",
    "        # Execute the cleaned Plotly code\n",
    "        exec(formatted_code, globals())  # Run in the global scope\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c63ee-dbed-4952-a3cb-307b7253b042",
   "metadata": {},
   "source": [
    "<h2>Handling Queries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4465622-b83a-4fce-b5b4-a9eb56d256e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query):\n",
    "    global df\n",
    "    if \"visualize\" in query.lower() or \"chart\" in query.lower() or \"graph\" in query.lower():\n",
    "        if df is None:\n",
    "            print(\"‚ùå Error: No file uploaded for visualization\")\n",
    "            return\n",
    "        generate_visualization(df, query)\n",
    "    else:\n",
    "        document = df.to_string() if df is not None else \"No document uploaded\"\n",
    "        history = \"\\n\".join([msg.content for msg in memory.chat_memory.messages])\n",
    "        \n",
    "        prompt_text = f\"Conversation history: {history}\\n\\nGiven the document: {document}, answer the following question: {query}\"\n",
    "        response = query_gemini(prompt_text)\n",
    "        \n",
    "        memory.chat_memory.add_user_message(query)\n",
    "        memory.chat_memory.add_ai_message(response)\n",
    "        \n",
    "        print(f\"ü§ñ Bot: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a1e93-89a0-4f42-bdf1-1c91e61e68f6",
   "metadata": {},
   "source": [
    "<h2>Simple Widget</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fde15f7-9109-4f28-be1f-ed53c5d612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload widget\n",
    "file_upload = FileUpload(accept='.csv,.pdf,.xlsx,.docx', multiple=False)\n",
    "upload_button = widgets.Button(description=\"Upload File\")\n",
    "\n",
    "# Query input widget\n",
    "query_input = widgets.Text(placeholder=\"Ask a question...\", layout=Layout(width=\"80%\"))\n",
    "ask_button = widgets.Button(description=\"Ask\")\n",
    "\n",
    "# Output widget\n",
    "output = Output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642bd02-bbd7-4a6f-9f21-b471c6a63500",
   "metadata": {},
   "source": [
    "<h2>Widget Interact Behavior</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bfeaa15-175e-406a-a435-cd0a1e8c728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handlers\n",
    "def on_upload_button_clicked(b):\n",
    "    global df\n",
    "    if not file_upload.value:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Error: No file selected.\")\n",
    "        return\n",
    "    \n",
    "    uploaded_file = file_upload.value[0]  # Extract first dictionary from tuple\n",
    "    filename = uploaded_file[\"name\"]\n",
    "    file_content = uploaded_file[\"content\"]\n",
    "\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(f\"üìÇ Uploaded File Name: {filename}\")\n",
    "        print(f\"üìè File Content Size: {len(file_content)} bytes\")\n",
    "\n",
    "    # Process the file\n",
    "    df = process_file({\"metadata\": {\"name\": filename}, \"content\": file_content})\n",
    "    \n",
    "    if df is not None:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(f\"‚úÖ File '{filename}' uploaded successfully!\")\n",
    "            print(df.head())  # Display first few rows of the DataFrame\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Error: Unsupported file type or failed to process file.\")\n",
    "\n",
    "def on_ask_button_clicked(b):\n",
    "    query = query_input.value.strip()\n",
    "    if query:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            handle_query(query)\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Error: Please enter a query.\")\n",
    "\n",
    "upload_button.on_click(on_upload_button_clicked)\n",
    "ask_button.on_click(on_ask_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6fbc9-dd7f-49cf-b035-c6acbfa2e661",
   "metadata": {},
   "source": [
    "<h2>Display the Widget Components</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b1a518-0b85-4148-8b75-037a76503dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cf004cc6bb4613b625acd3bd24ade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.csv,.pdf,.xlsx,.docx', description='Upload'), Button(description=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(VBox([file_upload, upload_button, query_input, ask_button, output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d03bfb-7ab0-454e-931c-5d06800221e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
